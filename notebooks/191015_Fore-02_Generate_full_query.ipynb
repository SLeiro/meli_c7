{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fore-02 Generate full query\n",
    "\n",
    "El objetivo de este notebook es testear la query definida para descargar el dataset full definido para los experimentos de forecasting de multiwarehouse. Específicamente nos interesa obtener todas las compras de un sitio dado (por ejemplo, MLB) y en un rango de fechas, y de ellas además de la información en la query básica, también queremos los siguientes campos:\n",
    "\n",
    "* Precio del item\n",
    "* Título del item al momento de la compra\n",
    "* Dominio\n",
    "* Marca\n",
    "* Modelo\n",
    "* Categoría\n",
    "* Product_id\n",
    "* Logística del envío\n",
    "* Origen\n",
    "* Seller_id\n",
    "* Buyer_id\n",
    "* Precio del envío\n",
    "* Promesa de entrega (speed y offset)\n",
    "\n",
    "Nuevamente, para los datos descargados, si la compra se realizó con Mercado Envíos existe un shipment_id y otra información del envío. De lo contrario, dichos campos quedan nulos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones y definiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from ml_forecasting.etl.base import FullExperimentDataSource\n",
    "from ml_forecasting.etl.dataset import DataPreparation\n",
    "from ml_forecasting.config import CONFIGS_BY_SITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "data_root = Path.home().joinpath('/alloc/data/fury_ml-forecasting/etl/raw_data/')\n",
    "site = 'MLB'\n",
    "teradata_user = os.environ['SECRET_TERADATA_USER']\n",
    "teradata_pass = os.environ['SECRET_TERADATA_PASS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desarrollo\n",
    "\n",
    "En primer lugar definimos el período de tiempo de compras que queremos descargar y chequeamos si el path donde vamos a guardar la información existe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_download = datetime.strptime('2019-09-07', '%Y-%m-%d')\n",
    "end_download = datetime.strptime('2019-09-14', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos los datos empleando la query definida en `ml_forecasting.etl.base`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = FullExperimentDataSource(teradata_user, teradata_pass, data_root, site)\n",
    "files = source.csvfiles(start_download, end_download, delta=(end_download - start_download).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    print('*', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos todos los datos guardados en el archivo, ahora vamos a llamar a `DataPreparation` del módulo `ml_forecasting.etl.dataset` para cargar y preparar el dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = DataPreparation(CONFIGS_BY_SITE[site])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep.load(files, cols=CONFIGS_BY_SITE[site]['DTYPES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el tamaño y un ejemplo del dataframe resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con la query básica tenemos más filas porque puede haber dos atributos (marca y modelo) para el mismo item y orden. Luego, debemos filtrar por `ord_order_id` diferentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_buys = df.drop_duplicates(subset='ord_order_id')\n",
    "print(\"Cantidad de órdenes diferentes: {}\".format(diff_buys.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando [descargamos los datos utilizando la query básica](../reports/191009_Fore-01_Generate_basic_query.html) teníamos 3392551 filas, donde cada fila corresponde a una orden. Luego, vemos que en la query full obtenemos la misma cantidad de datos.\n",
    "\n",
    "Por último, podemos comparar la cantidad de SI (items vendidos) que obtenemos a partir de la query generada con los datos registrados en el [dashboard de PortalBI](http://portalbi.ml.com/#/business_unit/2/dashboards/67) (en este caso, 4021412 SI):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI_query = diff_buys.bid_quantity_ok.sum()\n",
    "print(\"Cantidad de SI descargados en la query: {}\".format(SI_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SI_BI = 4021412\n",
    "print(\"Porcentaje de diferencia entre la query y el dashboard de BI: {:.3f}%\".format((SI_query-SI_BI)/SI_BI*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la diferencia es menor al 0.01%, por lo cual asumimos que la query generada es correcta y se obtienen todas las compras realizadas en el período de interés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "El objetivo de este notebook era testear la query definida para descargar el dataset full definido para los experimentos de forecasting de multiwarehouse. Utilizando la query definida en `ml_forecasting.etl.base` pudimos descargar los datos de interés de las compras de MLB para un rango de fechas (además de aquellos que ya se descargan en la query básica). Por otra parte, con la clase `DataPreparation` definida en `ml_forecasting.etl.dataset` pudimos cargar y preparar el dataframe. De esta manera, seteamos las bases (query y preparación de datos) para poder obtener los datos a utilizar en los futuros análisis de forecasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
